# ANLP_Final_Project_TaCL_BERT
This repository contains files and materials for the following tasks:

1. Fine-tuning the TaCL-BERT model on the SQuAD dataset. In addition, we performed a token representation self-similarity analysis on the wiki dataset to understand the token representations learned by both TaCL and BERT models. This analysis aims to determine if TaCL produces a more discriminative distribution of token representations compared to the standard BERT model.

To run the model use the intructions in [Tacl_Fine_Tune_Squad](https://github.com/sandeep-varma8029/ANLP_Final_Project_TaCL_BERT/tree/master/Tacl_Fine_Tune_Squad)
  
2. Conducting a qualitative analysis by sampling a sentence from Wikipedia and visualizing the self-similarity matrix produced by BERT-base and TaCL-base. This comparison helps to further understand the differences in the token representations captured by the two models.


To run the analysis follow the instructions in [Evaluation_and_Analysis](https://github.com/sandeep-varma8029/ANLP_Final_Project_TaCL_BERT/tree/master/Evaluation_and_Analysis)
  
  
# Project Team Memebers:
1. Sai Sandeep Varma Mudundi (G01352322)
2. Asra Naseem (G01349680)
3. Rajeev Priyatam Panchadula (G01333080)
